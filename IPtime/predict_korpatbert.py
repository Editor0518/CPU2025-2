import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import tensorflow as tf
from tensorflow import keras
from korpat_tokenizer import Tokenizer
import bert
from bert import BertModelLayer 


# ===== ê¸°ë³¸ ê²½ë¡œ ì„¤ì • =====
list_of_sub_labels = [
    'AAA', 'AAB', 'AAC',
    'ABA', 'ABB', 'ABC',
    'ACA', 'ACB', 'ACC',
    'ADA', 'ADB', 'ADC', 'ADD',
    'AEA', 'AEB', 'AEC', 'AED',
    'N'  # ë…¸ì´ì¦ˆ
]

list_of_mid_labels= ['AA', 'AB', 'AC', 'AD', 'AE', 'N']

CONFIG = {
    "noise": {
        "model_path": "korpatBERT_noise_filter.h5",
        "label": ['A', 'N'], #A=ìœ íš¨íŠ¹í—ˆ, N=ë…¸ì´ì¦ˆ
        "task_type": "binary"
    },
    "sub": {  # ì†Œë¶„ë¥˜
        "model_path": "korpatBERT_patent_model.h5",
        "label": list_of_sub_labels,  # ì†Œë¶„ë¥˜ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
        "task_type": "multi"
    },
    "mid": {  # ì¤‘ë¶„ë¥˜
        "model_path": "korpatBERT_mid_model.h5",
        "label": list_of_mid_labels,  # ì¤‘ë¶„ë¥˜ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
        "task_type": "multi"
    },
}

MAX_SEQ_LEN = 192
VOCAB_PATH = "./pretrained/korpat_vocab.txt"
tokenizer = Tokenizer(vocab_path=VOCAB_PATH, cased=True)

# ===== í…ìŠ¤íŠ¸ ì¸ì½”ë”© í•¨ìˆ˜ =====
def encode_texts(texts):
    input_ids = []
    for text in tqdm(texts):
        ids, _ = tokenizer.encode(text, max_len=MAX_SEQ_LEN)
        input_ids.append(ids)
    return np.array(input_ids)

# ===== ì˜ˆì¸¡ í•¨ìˆ˜ =====
def predict_labels(model, x_data, task_type, label_list):
    preds = model.predict(x_data)

    pred_labels = []
    pred_probs = []

    for p in preds:
        if task_type == "binary":
            prob = float(p[0])  # sigmoid ê²°ê³¼
            label = label_list[1] if prob >= 0.5 else label_list[0]  # ['A', 'N'] ê¸°ì¤€
            pred_labels.append(label)
            pred_probs.append(prob)
        else:  # multi-class
            idx = np.argmax(p)
            pred_labels.append(label_list[idx] if idx < len(label_list) else "UNKNOWN")
            pred_probs.append(float(np.max(p)))

    return pred_labels, pred_probs




# ===== ë©”ì¸ íë¦„ =====
def main():
    print("\nðŸ“Œ ì˜ˆì¸¡ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë…¸ì´ì¦ˆ ë¶„ë¥˜")
    print("2. ì†Œë¶„ë¥˜ ë¶„ë¥˜")
    print("3. ì¤‘ë¶„ë¥˜ ë¶„ë¥˜")
    choice = input("ì„ íƒ (1/2/3): ").strip()

    if choice == "1":
        mode = "noise"
    elif choice == "2":
        mode = "sub"
    elif choice == "3":
        mode = "mid"
    else:
        print("âŒ ìž˜ëª»ëœ ì„ íƒìž…ë‹ˆë‹¤.")
        return

    # ===== CSV ìž…ë ¥ =====
    file_path = input("\nðŸ“‚ ì˜ˆì¸¡í•  CSV íŒŒì¼ ê²½ë¡œë¥¼ ìž…ë ¥í•˜ì„¸ìš”: ").strip()
    if not os.path.exists(file_path):
        print("âŒ íŒŒì¼ì´ ì¡´ìž¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    df = pd.read_csv(file_path, encoding="cp949")
    df["text"] = df["title"].fillna('') + " " + df["korean_summary"].fillna('')
    x_data = encode_texts(df["text"].tolist())

    # ===== ëª¨ë¸ ë¡œë“œ =====
    print("ðŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")

    model = keras.models.load_model(CONFIG[mode]["model_path"], compile=False,
                                custom_objects={"BertModelLayer": BertModelLayer})

    labels = CONFIG[mode]["label"]
    task_type = CONFIG[mode]["task_type"]

    # ===== ì˜ˆì¸¡ =====
    print("ðŸ” ì˜ˆì¸¡ ì¤‘...")
    pred_labels, pred_probs = predict_labels(model, x_data, task_type, labels)
    df["label"] = pred_labels
    df["probability"] = pred_probs

    # ===== ê²°ê³¼ ìš”ì•½ ì¶œë ¥ =====
    print("\nðŸ“Š ì˜ˆì¸¡ëœ ì´ ìƒ˜í”Œ ìˆ˜:", len(df))
    print("ðŸ“ ì˜ˆì¸¡ëœ ë¼ë²¨ë³„ ê°œìˆ˜:")

    from collections import Counter
    label_counter = Counter(pred_labels)
    sorted_labels = sorted(label_counter.items(), key=lambda x: (-x[1], x[0]))  # ê°œìˆ˜ ë‚´ë¦¼ì°¨ìˆœ, ë¼ë²¨ ì´ë¦„ìˆœ

    for label, count in sorted_labels:
        if mode == "noise" and label == "N":
            print(f"  - N: {count}ê°œ")
            print(f"  - non-N: {len(df) - count}ê°œ")
            break
        else:
            print(f"  - {label}: {count}ê°œ")

    avg_conf = np.mean(pred_probs)
    print(f"\nðŸ“ˆ í‰ê·  ì˜ˆì¸¡ í™•ì‹ ë„ (Confidence): {avg_conf:.4f}")

    # ===== ê²°ê³¼ ì €ìž¥ =====
    output_path = f"prediction_result_{mode}.xlsx"
    df.to_excel(output_path, index=False, engine='openpyxl')
    print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ ì €ìž¥ë¨: {output_path}")



if __name__ == "__main__":
    main()
