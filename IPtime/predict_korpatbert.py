import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import tensorflow as tf
from tensorflow import keras
from korpat_tokenizer import Tokenizer
import bert
from bert import BertModelLayer 


# ===== ê¸°ë³¸ ê²½ë¡œ ì„¤ì • =====
list_of_sub_labels = [
    'AAA', 'AAB', 'AAC',
    'ABA', 'ABB', 'ABC',
    'ACA', 'ACB', 'ACC',
    'ADA', 'ADB', 'ADC', 'ADD',
    'AEA', 'AEB', 'AEC', 'AED',
    'N'  # ë…¸ì´ì¦ˆ
]

list_of_mid_labels= ['AA', 'AB', 'AC', 'AD', 'AE', 'N']

CONFIG = {
    "noise": {
        "model_path": "korpatBERT_noise_filter.h5",
        "label": ['A', 'N'], #A=ìœ íš¨íŠ¹í—ˆ, N=ë…¸ì´ì¦ˆ
        "task_type": "binary"
    },
    "sub": {  # ì†Œë¶„ë¥˜
        "model_path": "korpatBERT_patent_model.h5",
        "label": list_of_sub_labels,  # ì†Œë¶„ë¥˜ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
        "task_type": "multi"
    },
    "mid": {  # ì¤‘ë¶„ë¥˜
        "model_path": "korpatBERT_mid_model.h5",
        "label": list_of_mid_labels,  # ì¤‘ë¶„ë¥˜ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸
        "task_type": "multi"
    },
}

MAX_SEQ_LEN = 192
VOCAB_PATH = "./pretrained/korpat_vocab.txt"
tokenizer = Tokenizer(vocab_path=VOCAB_PATH, cased=True)

# ===== í…ìŠ¤íŠ¸ ì¸ì½”ë”© í•¨ìˆ˜ =====
def encode_texts(texts):
    input_ids = []
    for text in tqdm(texts):
        ids, _ = tokenizer.encode(text, max_len=MAX_SEQ_LEN)
        input_ids.append(ids)
    return np.array(input_ids)

# ===== ì˜ˆì¸¡ í•¨ìˆ˜ =====
def predict_labels(model, x_data, task_type, label_list):
    preds = model.predict(x_data)
    
    pred_labels = []
    pred_probs = []

    for p in preds:
        idx = np.argmax(p)
        if idx < len(label_list):
            pred_labels.append(label_list[idx])
        else:
            pred_labels.append("UNKNOWN")  # or skip
        pred_probs.append(float(np.max(p)))  # ìµœëŒ€ í™•ë¥  ì €ì¥

    return pred_labels, pred_probs



# ===== ë©”ì¸ íë¦„ =====
def main():
    print("\nğŸ“Œ ì˜ˆì¸¡ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë…¸ì´ì¦ˆ ë¶„ë¥˜")
    print("2. ì†Œë¶„ë¥˜ ë¶„ë¥˜")
    print("3. ì¤‘ë¶„ë¥˜ ë¶„ë¥˜")
    choice = input("ì„ íƒ (1/2/3): ").strip()

    if choice == "1":
        mode = "noise"
    elif choice == "2":
        mode = "sub"
    elif choice == "3":
        mode = "mid"
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return

    # ===== CSV ì…ë ¥ =====
    file_path = input("\nğŸ“‚ ì˜ˆì¸¡í•  CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not os.path.exists(file_path):
        print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    df = pd.read_csv(file_path, encoding="cp949")
    df["text"] = df["title"].fillna('') + " " + df["korean_summary"].fillna('')
    x_data = encode_texts(df["text"].tolist())

    # ===== ëª¨ë¸ ë¡œë“œ =====
    print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")

    model = keras.models.load_model(CONFIG[mode]["model_path"], compile=False,
                                custom_objects={"BertModelLayer": BertModelLayer})

    labels = CONFIG[mode]["label"]
    task_type = CONFIG[mode]["task_type"]

        # ===== ì˜ˆì¸¡ =====
    print("ğŸ” ì˜ˆì¸¡ ì¤‘...")
    pred_labels, pred_probs = predict_labels(model, x_data, task_type, labels)
    df["label"] = pred_labels
    df["probability"] = pred_probs

    # ===== ê²°ê³¼ ì €ì¥ =====
    output_path = f"prediction_result_{mode}.xlsx"
    df.to_excel(output_path, index=False, encoding='utf-8-sig', engine='openpyxl')
    print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {output_path}")


if __name__ == "__main__":
    main()
