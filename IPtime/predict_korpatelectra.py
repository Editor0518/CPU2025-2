import os
import numpy as np
import pandas as pd
from tqdm import tqdm
import torch
import torch.nn as nn
from torch.nn.functional import softmax
from transformers import ElectraTokenizer, ElectraForSequenceClassification
from transformers import ElectraModel

# ===== ê¸°ë³¸ ì„¤ì • =====
BATCH_SIZE = 8

list_of_sub_labels = [
    'AAA', 'AAB', 'AAC',
    'ABA', 'ABB', 'ABC',
    'ACA', 'ACB', 'ACC',
    'ADA', 'ADB', 'ADC', 'ADD',
    'AEA', 'AEB', 'AEC', 'AED',
    'N'
]

list_of_mid_labels = ['AA', 'AB', 'AC', 'AD', 'AE', 'N']

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

CONFIG = {
    "noise": {
        "model_path": "korpat_electra_noise_classifier.pth",
        "label": ['non-N', 'N'],
        "task_type": "binary"
    },
    "sub": {
        "model_path": "korpat_electra_classifier.pth",
        "label": list_of_sub_labels,
        "task_type": "multi"
    },
    "mid": {
        "model_path": "korpat_electra_mid_classifier.pth",
        "label": list_of_mid_labels,
        "task_type": "multi"
    },
}

MODEL_NAME = "monologg/koelectra-base-v3-discriminator"
MAX_SEQ_LEN = 192
tokenizer = ElectraTokenizer.from_pretrained(MODEL_NAME)


# ì¶”ë¡  ì½”ë“œì—ì„œ ElectraClassifier ìˆ˜ì •
class ElectraClassifier(nn.Module):
    def __init__(self, electra_model, num_labels):
        super().__init__()
        self.electra = electra_model
        self.classifier = nn.Linear(self.electra.config.hidden_size, num_labels)

    def forward(self, input_ids, attention_mask=None):
        outputs = self.electra(input_ids=input_ids, attention_mask=attention_mask)
        cls_vector = outputs.last_hidden_state[:, 0, :]
        return self.classifier(cls_vector)



# ===== í…ìŠ¤íŠ¸ ì¸ì½”ë”© =====
def encode_texts(texts):
    return tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=MAX_SEQ_LEN,
        return_tensors="pt"
    )

# ===== ì˜ˆì¸¡ í•¨ìˆ˜ =====
def predict_labels(model, inputs, label_list, batch_size=8, threshold=0.5):
    model.eval()
    model.to(device)

    input_ids = inputs['input_ids']
    attention_mask = inputs['attention_mask']

    num_samples = input_ids.size(0)
    pred_labels = []
    pred_probs = []

    with torch.no_grad():
        for i in tqdm(range(0, num_samples, batch_size)):
            batch_input_ids = input_ids[i:i+batch_size].to(device)
            batch_attention_mask = attention_mask[i:i+batch_size].to(device)

            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)
            logits = outputs  
            probs = torch.softmax(logits, dim=1)

             # 2ì§„ ë¶„ë¥˜ì¸ ê²½ìš° threshold ì ìš©
            if len(label_list) == 2:
                # probs[:,0]ì€ non-N í™•ë¥ 
                preds = (probs[:,0] >= threshold).long()
                # preds==1ì´ë©´ non-N, 0ì´ë©´ N (ì´ë•Œ label_list ìˆœì„œ ë§ì¶°ì•¼ í•¨)
                # ì—¬ê¸°ì„œ label_list ìˆœì„œê°€ ['non-N', 'N']ì´ë¼ë©´,
                # preds=1 â†’ non-N (index 0), preds=0 â†’ N (index 1) ì´ ì•„ë‹˜
                # preds = 1ì¼ ë•Œ non-Nìœ¼ë¡œ ë³´ê³  ì‹¶ë‹¤ë©´
                # preds = (probs[:,0] >= threshold).long() â†’ True=1 ì´ë¯€ë¡œ non-N ì¸ë±ìŠ¤ 0ê³¼ ì•ˆ ë§ìŒ
                # ê·¸ë˜ì„œ ì•„ë˜ì²˜ëŸ¼ ì¸ë±ìŠ¤ ë³€í™˜ í•„ìš”
                preds = torch.where(probs[:,0] >= threshold, torch.tensor(0), torch.tensor(1))
            else:
                max_probs, preds = torch.max(probs, dim=1)

            for pred_idx, prob in zip(preds.tolist(), probs.tolist()):
                pred_labels.append(label_list[pred_idx])
                # pred_probsëŠ” í•´ë‹¹ í´ë˜ìŠ¤ í™•ë¥ 
                pred_probs.append(prob[pred_idx])

            torch.cuda.empty_cache()

    return pred_labels, pred_probs




# ===== ë©”ì¸ íë¦„ =====
def main():
    print("\nğŸ“Œ ì˜ˆì¸¡ ì¢…ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("1. ë…¸ì´ì¦ˆ ë¶„ë¥˜")
    print("2. ì†Œë¶„ë¥˜ ë¶„ë¥˜")
    print("3. ì¤‘ë¶„ë¥˜ ë¶„ë¥˜")
    choice = input("ì„ íƒ (1/2/3): ").strip()

    if choice == "1":
        mode = "noise"
    elif choice == "2":
        mode = "sub"
    elif choice == "3":
        mode = "mid"
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return

    file_path = input("\nğŸ“‚ ì˜ˆì¸¡í•  CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
    if not os.path.exists(file_path):
        print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return

    df = pd.read_csv(file_path, encoding="cp949")
    df["text"] = df["title"].fillna('') + " " + df["korean_summary"].fillna('')
    texts = df["text"].tolist()

    print("ğŸ“¦ ëª¨ë¸ ë¡œë”© ì¤‘...")
    # ì¶”ë¡  ì‹œ ElectraModel ë¡œë“œ í›„ ì „ë‹¬
    base_model = ElectraModel.from_pretrained("monologg/koelectra-base-v3-discriminator")
    model = ElectraClassifier(base_model, num_labels=len(CONFIG[mode]["label"]))
    model.load_state_dict(torch.load(CONFIG[mode]["model_path"], map_location=device))
    model.to(device)
    model.eval()


    print("ğŸ§¼ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì¤‘...")
    inputs = encode_texts(texts)

    print("ğŸ” ì˜ˆì¸¡ ì¤‘...")
    pred_labels, pred_probs = predict_labels(model, inputs, CONFIG[mode]["label"], batch_size=BATCH_SIZE)

    df["label"] = pred_labels
    df["probability"] = pred_probs

    # ğŸ”¹ í†µê³„ ì •ë³´ ì¶œë ¥
    total = len(df)
    print(f"\nğŸ“Š ì˜ˆì¸¡ëœ ì´ ìƒ˜í”Œ ìˆ˜: {total}")
    
    label_counts = df["label"].value_counts()
    print("ğŸ“ ì˜ˆì¸¡ëœ ë¼ë²¨ë³„ ê°œìˆ˜:")
    for label, count in label_counts.items():
        print(f"  - {label}: {count}ê°œ")

    avg_prob = df["probability"].mean()
    print(f"\nğŸ“ˆ í‰ê·  ì˜ˆì¸¡ í™•ì‹ ë„ (Confidence): {avg_prob:.4f}")

    output_path = f"prediction_result_el_{mode}.xlsx"
    df.to_excel(output_path, index=False, engine='openpyxl')
    print(f"\nâœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼ íŒŒì¼ ì €ì¥ë¨: {output_path}")



if __name__ == "__main__":
    main()
