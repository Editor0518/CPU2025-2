import pandas as pd

# --- ë¹„êµ í•„ìš”í•œ ëª¨ë¸ì— ë”°ë¼ ì£¼ì„ í•´ì œ í›„ ì‚¬ìš©í•˜ê¸° ---
# KorPatBERT ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì„¤ì •
PREDICTION_SUBCLASS_FILE = "prediction_result_sub.xlsx"
PREDICTION_NOISE_FILE = "prediction_result_noise.xlsx"
PREDICTION_MIDCLASS_FILE = "prediction_result_mid.xlsx"

# KorPatELECTRA ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì„¤ì •
PREDICTION_SUBCLASS_FILE = "prediction_result_el_sub.xlsx"
PREDICTION_NOISE_FILE = "prediction_result_el_noise.xlsx"
PREDICTION_MIDCLASS_FILE = "prediction_result_el_mid.xlsx"
#----------------------------------------------------

ANSWER_FILE = "patent_data_finalN.csv"



# ===== ì •ë‹µ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° =====
df_true = pd.read_csv(ANSWER_FILE, encoding="cp949")
df_true = df_true[df_true['label'].notnull()].copy().reset_index(drop=True)

# ê³µí†µ í…ìŠ¤íŠ¸ ê¸°ì¤€ ì—´ ìƒì„± (title + korean_summary)
df_true["text"] = df_true["title"].fillna("") + " " + df_true["korean_summary"].fillna("")

# í…ìŠ¤íŠ¸ ê¸°ë°˜ ë§¤ì¹­ì„ ìœ„í•œ í‚¤ ìƒì„±
def normalize_text(text):
    return str(text).strip().replace(" ", "")

df_true["match_key"] = df_true["text"].apply(normalize_text)


# ===== ì˜ˆì¸¡ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜ =====
def load_prediction(file_path):
    df = pd.read_excel(file_path, engine='openpyxl')
    df["text"] = df["title"].fillna("") + " " + df["korean_summary"].fillna("")
    df["match_key"] = df["text"].apply(normalize_text)
    return df


# ===== ì •í™•ë„ ë¹„êµ í•¨ìˆ˜: Sub (ì •í™•íˆ ì¼ì¹˜) =====
def evaluate_sub(pred_df):
    merged = pd.merge(pred_df, df_true, on="match_key", suffixes=("_pred", "_true"))
    merged = merged.drop_duplicates(subset="match_key")
    merged = merged[merged["label_true"].str.strip() != ""]
    correct = (merged["label_pred"] == merged["label_true"]).sum()
    total = len(merged)
    acc = correct / total
    print("\nğŸ“˜ [ì†Œë¶„ë¥˜] ì •í™•ë„: %.4f (%d / %d)" % (acc, correct, total))


# ===== ì •í™•ë„ ë¹„êµ í•¨ìˆ˜: Noise ('N'ì¸ì§€ ì—¬ë¶€ë§Œ ë¹„êµ) =====
def evaluate_noise(pred_df):
    merged = pd.merge(pred_df, df_true, on="match_key", suffixes=("_pred", "_true"))
    merged = merged.drop_duplicates(subset="match_key")
    merged = merged[merged["label_true"].str.strip() != ""]

    def is_correct(pred, true):
        if pred == 'N':
            return true == 'N'
        else:
            return true != 'N'

    correct = sum(is_correct(p, t) for p, t in zip(merged["label_pred"], merged["label_true"]))
    total = len(merged)
    acc = correct / total
    print("\nğŸ“• [ë…¸ì´ì¦ˆ] ì •í™•ë„: %.4f (%d / %d)" % (acc, correct, total))


# ===== ì •í™•ë„ ë¹„êµ í•¨ìˆ˜: Mid (Nì´ë©´ N ë¹„êµ, ì•„ë‹ˆë©´ ì• ë‘ìë¦¬ ë¹„êµ) =====
def evaluate_mid(pred_df):
    merged = pd.merge(pred_df, df_true, on="match_key", suffixes=("_pred", "_true"))
    merged = merged.drop_duplicates(subset="match_key")
    merged = merged[merged["label_true"].str.strip() != ""]

    def is_correct(pred, true):
        if pred == 'N':
            return true == 'N'
        else:
            return true[:2] == pred

    correct = sum(is_correct(p, t) for p, t in zip(merged["label_pred"], merged["label_true"]))
    total = len(merged)
    acc = correct / total
    print("\nğŸ“™ [ì¤‘ë¶„ë¥˜] ì •í™•ë„: %.4f (%d / %d)" % (acc, correct, total))


# ===== ì‹¤í–‰ =====
evaluate_noise(load_prediction(PREDICTION_NOISE_FILE))
evaluate_sub(load_prediction(PREDICTION_SUBCLASS_FILE))
evaluate_mid(load_prediction(PREDICTION_MIDCLASS_FILE))
